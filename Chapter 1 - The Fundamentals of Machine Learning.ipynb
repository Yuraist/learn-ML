{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is Machine Learning?\n",
    "\n",
    "Machine Learning is the science and art of programming computers so they can learn from data.\n",
    "\n",
    "\"... field of study that gives computers the ability to learn without veing explicitly programmed.\" - Arthur Samuel, 1959\n",
    "\n",
    "\"A computer program is said to learn from experience E with respect to some task T and some perfomance measure P, if its perfomance on T, as measured by P, impoves with the exprience E.\" - Tom Mitchell, 1997\n",
    "\n",
    "# Types of Machine Learning Systems\n",
    "\n",
    "* Supervised, unsupervised, semisupervised and Reinforcement Learning - whether or not they are trained with human supervisor.\n",
    "* Online and batch learning - where or not they can learn incrementally on the fly.\n",
    "* Instance-based and model-based learning - whether they work by simplify comparing new data points to known data points, or instead detect patterns in the training data and build a predictive model.\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "In supervised learning, the training data you feed to the algorithm includes the desired solutions, called _labels_. \n",
    "\n",
    "Some important supervised learning algorithms:\n",
    "* k-Neares Neighbors\n",
    "* Linear Regression \n",
    "* Logistic Regression\n",
    "* Support Vector Machines (SVMs)\n",
    "* Decision Trees and Random Forests\n",
    "* Neural networks\n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "In unsupervised learning the training data is unlabeled. The system tries to learn without a teacher.\n",
    "\n",
    "Unsupervised Learning algorithms:\n",
    "* Clustering\n",
    "    - k-Means\n",
    "    - Hierarchical Cluster Analysis (HCA)\n",
    "    - Exprectation Maximization\n",
    "* Visualization and dimensionality reduction\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Kernel PCA\n",
    "    - Locally-Linear Embedding (LLE)\n",
    "    - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "* Association rule learning\n",
    "    - Apriori\n",
    "    - Eclat\n",
    "    \n",
    "__Dimensionality reduction__ is the task, in which the goal is to siplify the data without losing too much information. For example, a car's mileage may be very correlated with its age, so the dimensionality reduction algorthm will merge them into one feature. This is called _feature extraction_.\n",
    "\n",
    "__Anomaly detection__ – detecting unusial credit card transactions to preven fraud, catching manufacturing defects, automatically removing outliers from a dataset. \n",
    "\n",
    "__Association rule learning__ is the task, in which the goal is to dig into large amounts of data and discover interesting relations between attributes.\n",
    "\n",
    "### Semisupervised Learning\n",
    "\n",
    "Algorithms that deal with partially labeled trainig data. \n",
    "\n",
    "\n",
    "### Reinforcement Learning\n",
    "\n",
    "The learning system, called an agent in this context, can observe the environment, select and perform actions, and get rewards in return (or penalties in the form of negative rewards). It must then learn by itself what is the best strategy, called a policy, to get the most reward over time. A policy defines what action the agent should choose when it is in a given simulation.\n",
    "\n",
    "### Batch learning \n",
    "\n",
    "In batch learning, the system is incapable of learning incrementally: it must be trained using all the availabel data. This is called _offline learning_. \n",
    "\n",
    "### Online learning\n",
    "\n",
    "In online learning, you train the system incrementally by feeding it data instances sequentially, either individually or by small groups called mini-batches. Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives.\n",
    "\n",
    "__Learning rate__ is a parameter of online learning systems that defines how fast they should adapt to changing data. High learning rate – rapidly adapt to new data, but quickly forget. \n",
    "\n",
    "### Instance-based learning \n",
    "\n",
    "The system learns the examples by heart, then generalizes to new cases using a similarity measure. \n",
    "\n",
    "### Model-based learning\n",
    "\n",
    "Another way to generalize from a set of examples is to build a model of these examples, then use that model to make predictions.\n",
    "\n",
    "Linear model: $ \\theta_0 + \\theta_1 \\times x $\n",
    "\n",
    "__Utility function__ (or fitness function) is a function that measures how good the model is. \n",
    "\n",
    "__Cost function__ measures how bad it is.\n",
    "\n",
    "\n",
    "# Typical project workflow\n",
    "\n",
    "1. Load the data\n",
    "2. Prepare the data\n",
    "3. Visualize the data\n",
    "4. Select a model\n",
    "5. Train the model\n",
    "6. Make a prediction\n",
    "\n",
    "# Main Challenges of Machine Learning\n",
    "\n",
    "1. Insufficient Quantity of Trainig Data\n",
    "2. Nonrepresentative Training Data\n",
    "3. Poor-Quality Data\n",
    "4. Irrelevant Features\n",
    "5. Overfitting the Training Data (Overfitting: the model performs well on the trainig data, but it does not generalize)\n",
    "6. Underfitting the Trainig Data\n",
    "\n",
    "Constrainting a model to make it simpler and reduce the risk of overfitting is called _regularization_.\n",
    "\n",
    "The amount of regularization to apply during learning can be controlled by a hyperparameter.\n",
    "\n",
    "# Testing and Validating\n",
    "\n",
    "Split the data into two sets: the training set and the test set. As these names imply, you train your model using the training set, and you test it using the test set. The error rate on new cases is called the generalization error and by evaluating the model on the test set, you get an estimation of this error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
