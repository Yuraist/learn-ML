{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 10 - Artificial Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DTNrOFQtCOqx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Artificial Neural Networks\n",
        "\n",
        "## Training a DNN Using Plain TensorFlow\n",
        "\n",
        "The first step is the construction phase, building the TensorFlow graph. The second step is the execution phase, where we actually run the graph to train the model.\n",
        "\n",
        "### Construction Phase"
      ]
    },
    {
      "metadata": {
        "id": "MdqHJ4PuCOqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "n_inputs = 28 * 28 # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9fmJ5F3COrA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we can use placeholder nodes to represent the traing data and targets. We know that X will be a 2D tensor, with instances along the first dimension and features along the second dimension, and we know that the number of features is going to be 28x28, but we don't know yet how many instances each training batch will contain. So the shape of X is (None, n_inputs). Similary, we know that y will be a 1D tensor with one entry per instance, but again we don't know the size of the training batch at this point, so the shape is (None)."
      ]
    },
    {
      "metadata": {
        "id": "xWDVJ9JFCOrC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Placeholders"
      ]
    },
    {
      "metadata": {
        "id": "SP26AZbMCOrD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
        "y = tf.placeholder(tf.int64, shape=(None), name='y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3gYbz0JCOrH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The placoholder X will act as the input layer; during the execution phase, it will be replaced with one training batch at a time. "
      ]
    },
    {
      "metadata": {
        "id": "Fr_LsCNFCOrI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Neuron Layer"
      ]
    },
    {
      "metadata": {
        "id": "kQ11NJxLCOrJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def neuron_layer(X, n_neurons, name, activation=None):\n",
        "    # Create a name scope using the name of the layer.\n",
        "    with tf.name_scope(name):\n",
        "        n_inputs = int(X.get_shape()[1])\n",
        "        # Truncated normal distribution helps the algorithm converge \n",
        "        # much faster\n",
        "        stddev = 2 / np.sqrt(n_inputs)\n",
        "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
        "\n",
        "        # W is 2D tensor containing all the conection weights between\n",
        "        # each input and each neuron \n",
        "        W = tf.Variable(init, name='weights')\n",
        "        \n",
        "        # one bias parameter per neuron\n",
        "        b = tf.Variable(tf.zeros([n_neurons]), name='biases')\n",
        "\n",
        "        # Create a subgraph to compute z = X*W + b. \n",
        "        # This vectorized implementation will efficiently compute the \n",
        "        # weighted sums of the inputs in the batch in just one shot.\n",
        "        z = tf.matmul(X, W) + b\n",
        "        \n",
        "        # Return an actiovation function\n",
        "        if activation == 'relu':\n",
        "            return tf.nn.relu(z)\n",
        "        else:\n",
        "            return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELVjAkrJCOrQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have a function to create a neuron layer. We can create the __deep neural network__. The first hidden layer takes X as its input. The second takes the output of the first hidden layer as its input. And finally, the output layer takes the output of the second hidden layer as its input."
      ]
    },
    {
      "metadata": {
        "id": "zHIfks5cCOrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "-c8tzD3gCOrT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Use a name scope for clarity\n",
        "with tf.name_scope('dnn'):\n",
        "    hidden1 = neuron_layer(X, n_hidden1, 'hidden_1', activation='relu')\n",
        "    hidden2 = neuron_layer(hidden1, n_hidden2, 'hidden_2', activation='relu')\n",
        "    logits = neuron_layer(hidden2, n_outputs, 'outputs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZSNUgBWCOrW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow's `fully_connected()` function creates a fully conected layer, where all the inputs are connected to all the neurons in the layer. It takes care of creating the weights and biases variables, with the proper initialization strategy, and it uses the ReLU actiovation function by default (we can change this using the `activation_fn` argument)."
      ]
    },
    {
      "metadata": {
        "id": "tJnm42TcCOrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.contrib.layers import fully_connected\n",
        "\n",
        "with tf.name_scope('dnn'):\n",
        "    hidden1 = fully_connected(X, n_hidden1, scope='hidden1')\n",
        "    hidden2 = fully_connected(hidden1, n_hidden2, scope='hidden2')\n",
        "    logits = fully_connected(hidden2, n_outputs, scope='outputs', activation_fn=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtkgAj5VCOrb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `tensorflow.contrib` package contains many useful functions, but it is a place for experimental code that has not yet graduated to be part of the main TensorFlow API."
      ]
    },
    {
      "metadata": {
        "id": "7EZpAgP4COrd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ]
    },
    {
      "metadata": {
        "id": "Z3bC0ClkCOrd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('loss'):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eglQ9KJaCOri",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have the neural network model, we have the cost function, and now we need to define a `GradientDescentOptimizer` that will tweak the model parameters to minimize the cost function."
      ]
    },
    {
      "metadata": {
        "id": "egdrneRSCOrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "B6K0kercCOrk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope('train'):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSPZ3q8vCOrn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The last important step in the construction phase is to specify how to evaluate the model. First, for each instance, determine if the neural network's prediction is correct by checking whether or not the highest logit corresponds to the target class. For this we can use the `in_top_k()` function. "
      ]
    },
    {
      "metadata": {
        "id": "6ctYOb0ECOro",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Perfomance Measure"
      ]
    },
    {
      "metadata": {
        "id": "26vv3u0yCOrq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope('eval'):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xgcjrS9COr2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A node initializing all variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# A Saver to save our trained model parameters to disk\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmgGbIC6COr8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Execution Phase"
      ]
    },
    {
      "metadata": {
        "id": "SMZFTOkBCOr9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "be12b47c-183c-475c-960d-cb55d8784eac"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('/tmp/data/')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-54368a95c440>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sjw9qZkDCOsG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epochs = 400\n",
        "batch_size = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vs5ymxInCOsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6851
        },
        "outputId": "92430652-eafe-4927-9157-8322a0956e1b"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
        "                                             y: mnist.test.labels})\n",
        "        print('Epoch ', epoch, 'train accuracy ', acc_train, 'test accuracy ', acc_test)\n",
        "        \n",
        "    save_path = saver.save(sess, './my_model_final.ckpt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 train accuracy  0.88 test accuracy  0.9047\n",
            "Epoch  1 train accuracy  0.98 test accuracy  0.9228\n",
            "Epoch  2 train accuracy  0.96 test accuracy  0.929\n",
            "Epoch  3 train accuracy  0.92 test accuracy  0.9371\n",
            "Epoch  4 train accuracy  0.92 test accuracy  0.9424\n",
            "Epoch  5 train accuracy  1.0 test accuracy  0.9474\n",
            "Epoch  6 train accuracy  0.98 test accuracy  0.9498\n",
            "Epoch  7 train accuracy  0.94 test accuracy  0.9513\n",
            "Epoch  8 train accuracy  0.96 test accuracy  0.954\n",
            "Epoch  9 train accuracy  0.96 test accuracy  0.9571\n",
            "Epoch  10 train accuracy  0.96 test accuracy  0.9604\n",
            "Epoch  11 train accuracy  0.98 test accuracy  0.9618\n",
            "Epoch  12 train accuracy  0.98 test accuracy  0.9624\n",
            "Epoch  13 train accuracy  1.0 test accuracy  0.9653\n",
            "Epoch  14 train accuracy  0.94 test accuracy  0.9646\n",
            "Epoch  15 train accuracy  0.98 test accuracy  0.9651\n",
            "Epoch  16 train accuracy  0.94 test accuracy  0.9667\n",
            "Epoch  17 train accuracy  1.0 test accuracy  0.9682\n",
            "Epoch  18 train accuracy  0.98 test accuracy  0.9688\n",
            "Epoch  19 train accuracy  1.0 test accuracy  0.9694\n",
            "Epoch  20 train accuracy  1.0 test accuracy  0.9707\n",
            "Epoch  21 train accuracy  0.98 test accuracy  0.9717\n",
            "Epoch  22 train accuracy  0.98 test accuracy  0.9715\n",
            "Epoch  23 train accuracy  1.0 test accuracy  0.9725\n",
            "Epoch  24 train accuracy  1.0 test accuracy  0.9735\n",
            "Epoch  25 train accuracy  1.0 test accuracy  0.974\n",
            "Epoch  26 train accuracy  1.0 test accuracy  0.9744\n",
            "Epoch  27 train accuracy  1.0 test accuracy  0.9748\n",
            "Epoch  28 train accuracy  1.0 test accuracy  0.9748\n",
            "Epoch  29 train accuracy  1.0 test accuracy  0.9755\n",
            "Epoch  30 train accuracy  1.0 test accuracy  0.9761\n",
            "Epoch  31 train accuracy  1.0 test accuracy  0.9747\n",
            "Epoch  32 train accuracy  0.98 test accuracy  0.9758\n",
            "Epoch  33 train accuracy  1.0 test accuracy  0.977\n",
            "Epoch  34 train accuracy  1.0 test accuracy  0.9774\n",
            "Epoch  35 train accuracy  0.98 test accuracy  0.9786\n",
            "Epoch  36 train accuracy  1.0 test accuracy  0.976\n",
            "Epoch  37 train accuracy  1.0 test accuracy  0.9782\n",
            "Epoch  38 train accuracy  1.0 test accuracy  0.9772\n",
            "Epoch  39 train accuracy  1.0 test accuracy  0.9785\n",
            "Epoch  40 train accuracy  1.0 test accuracy  0.9786\n",
            "Epoch  41 train accuracy  0.96 test accuracy  0.9785\n",
            "Epoch  42 train accuracy  0.96 test accuracy  0.978\n",
            "Epoch  43 train accuracy  1.0 test accuracy  0.978\n",
            "Epoch  44 train accuracy  1.0 test accuracy  0.9787\n",
            "Epoch  45 train accuracy  1.0 test accuracy  0.9774\n",
            "Epoch  46 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  47 train accuracy  1.0 test accuracy  0.9793\n",
            "Epoch  48 train accuracy  1.0 test accuracy  0.9785\n",
            "Epoch  49 train accuracy  1.0 test accuracy  0.9785\n",
            "Epoch  50 train accuracy  1.0 test accuracy  0.979\n",
            "Epoch  51 train accuracy  1.0 test accuracy  0.98\n",
            "Epoch  52 train accuracy  1.0 test accuracy  0.979\n",
            "Epoch  53 train accuracy  1.0 test accuracy  0.9793\n",
            "Epoch  54 train accuracy  1.0 test accuracy  0.979\n",
            "Epoch  55 train accuracy  1.0 test accuracy  0.979\n",
            "Epoch  56 train accuracy  1.0 test accuracy  0.9799\n",
            "Epoch  57 train accuracy  1.0 test accuracy  0.9793\n",
            "Epoch  58 train accuracy  1.0 test accuracy  0.9794\n",
            "Epoch  59 train accuracy  1.0 test accuracy  0.9797\n",
            "Epoch  60 train accuracy  1.0 test accuracy  0.9791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  61 train accuracy  1.0 test accuracy  0.98\n",
            "Epoch  62 train accuracy  1.0 test accuracy  0.9797\n",
            "Epoch  63 train accuracy  1.0 test accuracy  0.9798\n",
            "Epoch  64 train accuracy  1.0 test accuracy  0.9795\n",
            "Epoch  65 train accuracy  1.0 test accuracy  0.9801\n",
            "Epoch  66 train accuracy  0.98 test accuracy  0.9796\n",
            "Epoch  67 train accuracy  1.0 test accuracy  0.9806\n",
            "Epoch  68 train accuracy  1.0 test accuracy  0.9793\n",
            "Epoch  69 train accuracy  0.98 test accuracy  0.9804\n",
            "Epoch  70 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  71 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  72 train accuracy  1.0 test accuracy  0.9799\n",
            "Epoch  73 train accuracy  1.0 test accuracy  0.9803\n",
            "Epoch  74 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  75 train accuracy  1.0 test accuracy  0.9803\n",
            "Epoch  76 train accuracy  1.0 test accuracy  0.9796\n",
            "Epoch  77 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  78 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  79 train accuracy  1.0 test accuracy  0.9804\n",
            "Epoch  80 train accuracy  1.0 test accuracy  0.9799\n",
            "Epoch  81 train accuracy  0.98 test accuracy  0.9806\n",
            "Epoch  82 train accuracy  1.0 test accuracy  0.9799\n",
            "Epoch  83 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  84 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  85 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  86 train accuracy  1.0 test accuracy  0.9799\n",
            "Epoch  87 train accuracy  1.0 test accuracy  0.9801\n",
            "Epoch  88 train accuracy  1.0 test accuracy  0.9804\n",
            "Epoch  89 train accuracy  1.0 test accuracy  0.9803\n",
            "Epoch  90 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  91 train accuracy  1.0 test accuracy  0.9801\n",
            "Epoch  92 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  93 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  94 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  95 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  96 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  97 train accuracy  1.0 test accuracy  0.9803\n",
            "Epoch  98 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  99 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  100 train accuracy  1.0 test accuracy  0.9803\n",
            "Epoch  101 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  102 train accuracy  1.0 test accuracy  0.9803\n",
            "Epoch  103 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  104 train accuracy  1.0 test accuracy  0.9806\n",
            "Epoch  105 train accuracy  1.0 test accuracy  0.9807\n",
            "Epoch  106 train accuracy  1.0 test accuracy  0.9804\n",
            "Epoch  107 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  108 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  109 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  110 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  111 train accuracy  1.0 test accuracy  0.9806\n",
            "Epoch  112 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  113 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  114 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  115 train accuracy  1.0 test accuracy  0.9804\n",
            "Epoch  116 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  117 train accuracy  1.0 test accuracy  0.9807\n",
            "Epoch  118 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  119 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  120 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  121 train accuracy  1.0 test accuracy  0.981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  122 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  123 train accuracy  1.0 test accuracy  0.9807\n",
            "Epoch  124 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  125 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  126 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  127 train accuracy  1.0 test accuracy  0.9806\n",
            "Epoch  128 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  129 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  130 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  131 train accuracy  1.0 test accuracy  0.9805\n",
            "Epoch  132 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  133 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  134 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  135 train accuracy  1.0 test accuracy  0.9807\n",
            "Epoch  136 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  137 train accuracy  1.0 test accuracy  0.9806\n",
            "Epoch  138 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  139 train accuracy  1.0 test accuracy  0.9802\n",
            "Epoch  140 train accuracy  1.0 test accuracy  0.9806\n",
            "Epoch  141 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  142 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  143 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  144 train accuracy  1.0 test accuracy  0.9804\n",
            "Epoch  145 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  146 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  147 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  148 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  149 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  150 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  151 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  152 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  153 train accuracy  1.0 test accuracy  0.9807\n",
            "Epoch  154 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  155 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  156 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  157 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  158 train accuracy  1.0 test accuracy  0.9807\n",
            "Epoch  159 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  160 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  161 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  162 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  163 train accuracy  1.0 test accuracy  0.9808\n",
            "Epoch  164 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  165 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  166 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  167 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  168 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  169 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  170 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  171 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  172 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  173 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  174 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  175 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  176 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  177 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  178 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  179 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  180 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  181 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  182 train accuracy  1.0 test accuracy  0.9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  183 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  184 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  185 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  186 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  187 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  188 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  189 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  190 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  191 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  192 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  193 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  194 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  195 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  196 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  197 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  198 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  199 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  200 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  201 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  202 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  203 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  204 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  205 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  206 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  207 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  208 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  209 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  210 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  211 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  212 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  213 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  214 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  215 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  216 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  217 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  218 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  219 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  220 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  221 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  222 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  223 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  224 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  225 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  226 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  227 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  228 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  229 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  230 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  231 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  232 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  233 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  234 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  235 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  236 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  237 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  238 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  239 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  240 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  241 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  242 train accuracy  1.0 test accuracy  0.9813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  243 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  244 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  245 train accuracy  1.0 test accuracy  0.981\n",
            "Epoch  246 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  247 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  248 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  249 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  250 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  251 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  252 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  253 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  254 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  255 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  256 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  257 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  258 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  259 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  260 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  261 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  262 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  263 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  264 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  265 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  266 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  267 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  268 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  269 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  270 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  271 train accuracy  1.0 test accuracy  0.9818\n",
            "Epoch  272 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  273 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  274 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  275 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  276 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  277 train accuracy  1.0 test accuracy  0.9817\n",
            "Epoch  278 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  279 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  280 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  281 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  282 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  283 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  284 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  285 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  286 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  287 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  288 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  289 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  290 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  291 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  292 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  293 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  294 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  295 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  296 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  297 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  298 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  299 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  300 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  301 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  302 train accuracy  1.0 test accuracy  0.9813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  303 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  304 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  305 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  306 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  307 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  308 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  309 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  310 train accuracy  1.0 test accuracy  0.9817\n",
            "Epoch  311 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  312 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  313 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  314 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  315 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  316 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  317 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  318 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  319 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  320 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  321 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  322 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  323 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  324 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  325 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  326 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  327 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  328 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  329 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  330 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  331 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  332 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  333 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  334 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  335 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  336 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  337 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  338 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  339 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  340 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  341 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  342 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  343 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  344 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  345 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  346 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  347 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  348 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  349 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  350 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  351 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  352 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  353 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  354 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  355 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  356 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  357 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  358 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  359 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  360 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  361 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  362 train accuracy  1.0 test accuracy  0.9814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  363 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  364 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  365 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  366 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  367 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  368 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  369 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  370 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  371 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  372 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  373 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  374 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  375 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  376 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  377 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  378 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  379 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  380 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  381 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  382 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  383 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  384 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  385 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  386 train accuracy  1.0 test accuracy  0.9816\n",
            "Epoch  387 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  388 train accuracy  1.0 test accuracy  0.9812\n",
            "Epoch  389 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  390 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  391 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  392 train accuracy  1.0 test accuracy  0.9811\n",
            "Epoch  393 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  394 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  395 train accuracy  1.0 test accuracy  0.9814\n",
            "Epoch  396 train accuracy  1.0 test accuracy  0.9809\n",
            "Epoch  397 train accuracy  1.0 test accuracy  0.9813\n",
            "Epoch  398 train accuracy  1.0 test accuracy  0.9815\n",
            "Epoch  399 train accuracy  1.0 test accuracy  0.9812\n",
            "CPU times: user 30min 40s, sys: 2min 13s, total: 32min 53s\n",
            "Wall time: 20min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RSUtk96FCOsR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing on Macbook Pro 13 (Early 2015) with 2,7 GHz Intel Core i5:\n",
        "```\n",
        "CPU times: user 37min 3s, sys: 2min 46s, total: 39min 49s\n",
        "Wall time: 17min 57s\n",
        "```\n",
        "Testing on DigitalOcean Droplet with 1CPU:\n",
        "```\n",
        "CPU times: user 23min 10s, sys: 55.7 s, total: 24min 5s\n",
        "Wall time: 24min 7s\n",
        "```\n",
        "\n",
        "Testing on Google Colab with GPU (?):\n",
        "```\n",
        "CPU times: user 14min 47s, sys: 4min 10s, total: 18min 57s\n",
        "Wall time: 14min 30s\n",
        "```\n",
        "\n",
        "Testing on Google Colab without GPU: \n",
        "```\n",
        "CPU times: user 30min 40s, sys: 2min 13s, total: 32min 53s\n",
        "Wall time: 20min 16s\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "S98xAdMECOsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Using the Neural Network\n",
        "\n",
        "Now that the neural network is trained, we can use it to make predictions. To do that, we cat reuse the same construction phase, but change the execution phase."
      ]
    },
    {
      "metadata": {
        "id": "zxsOQ36gCOsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f722310e-3a6e-49e3-843c-7c352a950546"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    # Load the model parameters from disk\n",
        "    saver.restore(sess, './my_model_final.ckpt')\n",
        "    \n",
        "    # Load new images\n",
        "    X_new_scaled = mnist.test.images[:20]\n",
        "    \n",
        "    # Evaluate the logits node\n",
        "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
        "    \n",
        "    # Pick the class that has the highest logit value\n",
        "    y_pred = np.argmax(Z, axis=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Tub-0PQCOsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2137424a-3feb-4308-f9df-2868e660425e"
      },
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "xviYBcwoCOsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b2dda5b-1ecc-47bb-b7a9-ad50ab4fdaf6"
      },
      "cell_type": "code",
      "source": [
        "mnist.test.labels[:20]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4],\n",
              "      dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}